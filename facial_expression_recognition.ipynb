{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initializations and Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle wandb onnx -Uq\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/ML/kaggle/kaggle.json ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip facial-expression-recognition-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir facial-expression-recognition-dataset\n",
    "!mv example_submission.csv facial-expression-recognition-dataset/\n",
    "!mv icml_face_data.csv facial-expression-recognition-dataset/\n",
    "!mv test.csv facial-expression-recognition-dataset/\n",
    "!mv train.csv facial-expression-recognition-dataset/\n",
    "!mv fer2013.tar.gz facial-expression-recognition-dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I should have directory `facial-expression-recognition-dataset` containing dataset files from kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports\n",
    "Lets start by getting all our imports, keep in mind that PyTorch is not automatically detects and trains on GPU, you have to tell it to use cuda. In case you want to train on Mac Silicon replace cuda with mps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Main PyTorch Library\n",
    "from torch import nn # Used for creating the layers and loss function\n",
    "from torch.optim import Adam # Adam Optimizer\n",
    "import torchvision.transforms as transforms # Transform function used to modify and preprocess all the images\n",
    "from torch.utils.data import Dataset, DataLoader # Dataset class and DataLoader for creating the objects\n",
    "from sklearn.preprocessing import LabelEncoder # Label Encoder to encode the classes from strings to numbers\n",
    "import matplotlib.pyplot as plt # Used for visualizing the images and plotting the training progress\n",
    "from PIL import Image # Used to read the images from the directory\n",
    "import pandas as pd # Used to read/create dataframes (csv) and process tabular data\n",
    "import numpy as np # preprocessing and numerical/mathematical operations\n",
    "import os # Used to read the images path from the directory\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac\n",
    "print(\"Device available: \", device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
